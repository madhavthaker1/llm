{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6af76bd7-f705-4b19-866e-5ec11f8dd9da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606986be-fd43-4b0f-b69b-02250e57e4b0",
   "metadata": {},
   "source": [
    "### Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae9d6495-af97-405d-b4d6-63b322cb82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U torch datasets transformers tensorflow langchain playwright html2text sentence_transformers faiss-cpu\n",
    "!pip install -q accelerate==0.21.0 peft==0.4.0 bitsandbytes==0.40.2 trl==0.4.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacdda41-708b-4af8-88a9-5056cbd08bf4",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "505ca9a3-8c27-442e-bca6-154a65186d01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-31 00:32:28.905193: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-31 00:32:28.956729: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-31 00:32:28.956766: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-31 00:32:28.958157: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-31 00:32:28.966585: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.llms import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180f8d4e-a8bf-4389-b046-9827b310a3b3",
   "metadata": {},
   "source": [
    "### Load quantized Mistal 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f94e97-7e58-4253-9376-73af6f36e139",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f465bdfb643e0a6e770239f10ff2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a52d88639d14931a335ad7ae08749f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e025729b7f8d4eb3b18cfe6ff8b146f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d557b150898b48f5acda550f70bc0492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac0ddd93e264f4b963cbe974576de7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a434dd208bfe469ba57564799ff09d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8567b26b596e49cfafe1f110ac54b102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33977147fad4cfbb05e17ce09dedcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54d94f225d741b7963606aebbaa86fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054c2930e33644aea161c355dbce94d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3198efa4fa0646c79ae0fe7a59bf3415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0924be95ab6e4f15b3ea9f7dd4bd0273",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################################################\n",
    "# Tokenizer\n",
    "#################################################################\n",
    "\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.2'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "#################################################################\n",
    "# bitsandbytes parameters\n",
    "#################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False\n",
    "\n",
    "#################################################################\n",
    "# Set up quantization config\n",
    "#################################################################\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "#################################################################\n",
    "# Load pre-trained config\n",
    "#################################################################\n",
    "mistral_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb199a-a537-4bd7-9888-d43a84c8ff69",
   "metadata": {},
   "source": [
    "### Count number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d2a86e-69e8-496f-b388-853168537c20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(mistral_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a38c760-f5c8-49c6-9c0c-80719557fee5",
   "metadata": {},
   "source": [
    "### Build Mistral text generation pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c613429-9e6c-4a1e-bc9c-579eb152434b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "standalone_query_generation_pipeline = pipeline(\n",
    " model=mistral_model,\n",
    " tokenizer=tokenizer,\n",
    " task=\"text-generation\",\n",
    " temperature=0.0,\n",
    " repetition_penalty=1.1,\n",
    " return_full_text=True,\n",
    " max_new_tokens=1000,\n",
    ")\n",
    "standalone_query_generation_llm = HuggingFacePipeline(pipeline=standalone_query_generation_pipeline)\n",
    "\n",
    "response_generation_pipeline = pipeline(\n",
    " model=mistral_model,\n",
    " tokenizer=tokenizer,\n",
    " task=\"text-generation\",\n",
    " temperature=0.2,\n",
    " repetition_penalty=1.1,\n",
    " return_full_text=True,\n",
    " max_new_tokens=1000,\n",
    ")\n",
    "response_generation_llm = HuggingFacePipeline(pipeline=response_generation_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a07789-78f5-498c-987b-9ed3eb459fe6",
   "metadata": {},
   "source": [
    "### Load and chunk documents. Load chunked documents into FAISS index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bd0398-f7b5-479c-9ed9-2341e4701fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!playwright install \n",
    "!playwright install-deps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a2e41f-aee3-47ff-92a1-74970f3b313a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Articles to index\n",
    "articles = [\"https://www.fantasypros.com/2023/12/fantasy-football-panic-meter-patrick-mahomes-austin-ekeler-stefon-diggs-travis-etienne/\",]\n",
    "\n",
    "# Scrapes the blogs above\n",
    "loader = AsyncChromiumLoader(articles)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff328fea-b7c7-4ca3-915c-39c0ebaa2f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4148, which is longer than the specified 800\n",
      "Created a chunk of size 898, which is longer than the specified 800\n"
     ]
    }
   ],
   "source": [
    "# Converts HTML to plain text \n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "\n",
    "# Chunk text\n",
    "text_splitter = CharacterTextSplitter(chunk_size=800, \n",
    "                                      chunk_overlap=0)\n",
    "chunked_documents = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "# Load chunked documents into the FAISS index\n",
    "db = FAISS.from_documents(chunked_documents, \n",
    "                          HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))\n",
    "\n",
    "retriever = db.as_retriever(k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d54a0b-bf6c-4a24-b888-4c3283b9ccf6",
   "metadata": {},
   "source": [
    "### Create PromptTemplate and LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "223cf384-5c03-4399-aa64-4607f5bd2de2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.schema import format_document\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd592e9-8f84-400e-963f-2a449e41f1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_template = \"\"\"\n",
    "[INST] \n",
    "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language, that can be used to query a FAISS index. This query will be used to retrieve documents with additional context. \n",
    "\n",
    "Let me share a couple examples that will be important. \n",
    "\n",
    "If you do not see any chat history, you MUST return the \"Follow Up Input\" as is:\n",
    "\n",
    "```\n",
    "Chat History:\n",
    "\n",
    "Follow Up Input: How is Lawrence doing?\n",
    "Standalone Question:\n",
    "How is Lawrence doing?\n",
    "```\n",
    "\n",
    "If this is the second question onwards, you should properly rephrase the question like this:\n",
    "\n",
    "```\n",
    "Chat History:\n",
    "Human: How is Lawrence doing?\n",
    "AI: \n",
    "Lawrence is injured and out for the season.\n",
    "\n",
    "Follow Up Input: What was his injurt?\n",
    "Standalone Question:\n",
    "What was Lawrence's injury?\n",
    "```\n",
    "\n",
    "Now, with those examples, here is the actual chat history and input question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\n",
    "[your response here]\n",
    "[/INST] \n",
    "\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb05ea7-cc5b-4e3a-978c-cecd65d6488c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "[INST] \n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "[/INST] \n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c848fc35-37b5-47d5-98b4-b34b6f4c7155",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b18f66e5-684e-481b-a169-6289297dca6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    " return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")\n",
    "\n",
    "# First we add a step to load memory\n",
    "# This adds a \"memory\" key to the input object\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "# Now we calculate the standalone question\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | standalone_query_generation_llm,\n",
    "}\n",
    "# Now we retrieve the documents\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "# Now we construct the inputs for the final prompt\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# And finally, we do the part that returns the answers\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | response_generation_llm,\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "    \"context\": final_inputs[\"context\"]\n",
    "}\n",
    "# And now we put it all together!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cdec6aad-8836-4a22-a09c-62f0e283d79e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_conversational_rag(question, chain, memory):\n",
    "    \"\"\"\n",
    "    Calls a conversational RAG (Retrieval-Augmented Generation) model to generate an answer to a given question.\n",
    "\n",
    "    This function sends a question to the RAG model, retrieves the answer, and stores the question-answer pair in memory \n",
    "    for context in future interactions.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The question to be answered by the RAG model.\n",
    "    chain (LangChain object): An instance of LangChain which encapsulates the RAG model and its functionality.\n",
    "    memory (Memory object): An object used for storing the context of the conversation.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the generated answer from the RAG model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prepare the input for the RAG model\n",
    "    inputs = {\"question\": question}\n",
    "\n",
    "    # Invoke the RAG model to get an answer\n",
    "    result = chain.invoke(inputs)\n",
    "    \n",
    "    # Save the current question and its answer to memory for future context\n",
    "    memory.save_context(inputs, {\"answer\": result[\"answer\"]})\n",
    "    \n",
    "    # Return the result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "757549b7-0ba7-4577-85f7-70b90290b40e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'In the context provided, Patrick Mahomes, the quarterback for the Kansas City Chiefs, is currently ranked as QB10 for the 2023 fantasy football season. He has finished with less than 17 points in seven out of his last eight games. However, despite his recent struggles, he still offers a high upside due to his talent. There are other quarterbacks, such as Baker Mayfield and Joe Flacco, who have shown a better floor lately. Mayfield is averaging 22.9 PPG over his last three games, while Flacco is averaging 351 pass YPG and 20.6 PPG during the same period.',\n",
       " 'question': \"Standalone Question:\\nHow is Mahomes doing?\\n\\n(Note: Mahomes is a common name, so it's essential to specify which Mahomes is being referred to if there are multiple options.)\",\n",
       " 'context': '|\\n\\n2 min read\\n\\nNext Up - **Fantasy Football NFL Week 17 Injury Report & Outlook (2023)**\\n\\nNext Article  \\n\\nThis website uses cookies to provide basic functionality, enhance user\\nexperience, and to analyze performance and traffic. We also share information\\nabout your use of our site with our social media, advertising, and analytics\\npartners.  \\n  \\nBy using this website you agree to our Terms of Use.\\n\\nDo Not Sell My Personal Information Accept Cookies\\n\\n**Patrick Mahomes (QB – KC)| Panic Meter: 3 **\\n\\nSooner or later the Chiefs have to figure it out, right? We’ve been asking\\nourselves this question for 8 weeks now and nothing has changed. In week 16,\\nMahomes finished with less than 17 points for the seventh time in his last\\neight games. He is QB10 on the season. No QB will offer you the same upside as\\nMahomes, but there are several likely-available players that have displayed a\\nmuch higher floor as of late. Consider these options:\\n\\n  * Baker Mayfield\\n\\n(QB – TB): averaging 22.9 PPG over his last three games.\\n\\n  * Joe Flacco\\n\\n(QB – CLE): averaging 351 pass YPG and 20.6 PPG over his last three games.\\n\\n**Austin Ekeler (RB – LAC) | Panic Meter: 3**\\n\\n* Weekly Fantasy Football Expert Rankings\\n  * Waiver Wire Picks\\n  * Fantasy Football Start/Sit Advice\\n  * Fantasy Football Trade Tools\\n\\n__ Follow\\n\\n## More Articles\\n\\n### Fantasy Football NFL Week 17 Injury Report & Outlook (2023)\\n\\nby **Deepak Chona - MD** | 2 min read\\n\\n### Fantasy Football Week 17 Rankings, Grades & Start/Sit Advice (2023)\\n\\nby **FantasyPros Staff** | 15+ min read\\n\\n### NFL DFS Week 17 Stacking Advice & Picks (2023 Fantasy Football)\\n\\nby **Joe Pepe** | 1 min read\\n\\n### Last-Minute Fantasy Football Advice for Week 17 (2023)\\n\\nby **FantasyPros Staff** | 2 min read\\n\\n# About Author\\n\\nTim Brosnan\\n\\nTim Brosnan is a featured writer at FantasyPros, providing unique insights and\\nin-depth analysis.\\n\\n# Recent Articles\\n\\nFantasy Football NFL Week 17 Injury Report & Outlook (2023)\\n\\n14h ago\\n\\nFantasy Football Week 17 Rankings, Grades & Start/Sit Advice (2023)\\n\\n14h ago'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"how is maholmes doing?\"\n",
    "call_conversational_rag(question, final_chain, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b9e003-36d1-4355-87a6-498416cee446",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': \"Based on the context provided, two quarterbacks who have shown better performance than Patrick Mahomes recently are Baker Mayfield and Joe Flacco. Mayfield is averaging 22.9 points per game (PPG) over his last three games, while Flacco is averaging 351 passing yards per game (YPG) and 20.6 PPG over the same period. These numbers suggest that Mayfield and Flacco may provide a higher floor compared to Mahomes' inconsistent performances. However, it's essential to consider other factors such as team situation, opponent matchups, and personal preferences before making any decisions.\",\n",
       " 'question': 'Which quarterbacks have shown better performance than Patrick Mahomes recently, and could be considered as potential alternatives?',\n",
       " 'context': '**Patrick Mahomes (QB – KC)| Panic Meter: 3 **\\n\\nSooner or later the Chiefs have to figure it out, right? We’ve been asking\\nourselves this question for 8 weeks now and nothing has changed. In week 16,\\nMahomes finished with less than 17 points for the seventh time in his last\\neight games. He is QB10 on the season. No QB will offer you the same upside as\\nMahomes, but there are several likely-available players that have displayed a\\nmuch higher floor as of late. Consider these options:\\n\\n  * Baker Mayfield\\n\\n(QB – TB): averaging 22.9 PPG over his last three games.\\n\\n  * Joe Flacco\\n\\n(QB – CLE): averaging 351 pass YPG and 20.6 PPG over his last three games.\\n\\n**Austin Ekeler (RB – LAC) | Panic Meter: 3**\\n\\nFantasy Football Panic Meter: Patrick Mahomes, Austin Ekeler, Stefon Diggs,\\nTravis Etienne | FantasyPros **PANIC METER GRADE** | **STRATEGY/PLAN OF\\nACTION**  \\n---|---  \\n0 | This past week WAS not ideal, but it can be chalked up as an anomaly.\\nPanic is not necessary.  \\n1 | Panic is creeping up. It’s not time to sound the alarm yet, but it is\\nsomething to be aware of. Said player should still be considered a starter but\\nis now under surveillance.  \\n2 | Officially panicked, taking things week by week, considering a Plan B,\\nexploring trade options or benching for a more reliable option.  \\n3 | Fire sale. Actively seeking a trade while the player in question still has\\nvalue. They are no longer a trustworthy starter. In some cases, a borderline\\ndrop-candidate.  \\n4 | Sever all ties. Smash the drop button so hard that the man ends up in the\\nshadow realm.  \\n  \\n## **Fantasy Football Panic Meter**\\n\\n#  Fantasy Football Panic Meter: Patrick Mahomes, Austin Ekeler, Stefon Diggs,\\nTravis Etienne\\n\\nby  Tim Brosnan  |  Dec 26, 2023\\n\\nWe currently live in a world where you can’t trust (spoiler alert) Patrick\\nMahomes\\n\\n, Austin Ekeler\\n\\nor Stefon Diggs\\n\\nin your starting lineup. Up is down, hot is cold, Joe Flacco\\n\\nis in MVP-form and we’re all just trying to piece things together.\\n\\nThis week, on a special edition of ‘The Panic Meter’ we will feature several\\nplayers you should be panicked enough to avoid starting, as well as\\nstreaming/bench alternatives to replace them.\\n\\nIf you’ve made it this far, congratulations. If you fell short, you probably\\nhave a player on this list.\\n\\nWithout further ado, here is this week’s fantasy football panic meter.\\n\\nClyde Edwards-Helaire\\n\\n(illness) listed questionable for Week 17\\n\\nAlvin Kamara\\n\\n(illness) listed as questionable for Week 17\\n\\nStefon Diggs\\n\\nGets rest day Friday, not on injury report\\n\\nJordan Addison\\n\\n(ankle) listed questionable for Week 17\\n\\nMason Rudolph\\n\\nTo start in Week 17\\n\\nSee all news\\n\\n# Consensus Rankings\\n\\n  * NFL\\n  * MLB\\n  * NBA\\n  * NHL\\n\\n  1. Christian McCaffrey\\n\\nRB — SF\\n\\n  2. Kyren Williams\\n\\nRB — LAR\\n\\n  3. CeeDee Lamb\\n\\nWR — DAL\\n\\n  4. Tyreek Hill\\n\\nWR — MIA\\n\\n__\\n\\n  5. Rachaad White\\n\\nRB — TB\\n\\n  6. Travis Etienne Jr.\\n\\nRB — JAC\\n\\n  7. James Cook\\n\\nRB — BUF\\n\\n  8. Justin Jefferson\\n\\nWR — MIN\\n\\n__\\n\\n  9. Jonathan Taylor\\n\\nRB — IND\\n\\n__\\n\\n  10. Jahmyr Gibbs\\n\\nRB — DET\\n\\n__\\n\\nView all Flex Rankings\\n\\nFantasy football\\n\\n# Who Should I Start\\n\\n__\\n\\n__\\n\\nSee Advice  __\\n\\n# Product Updates'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who are some good alternatives to him?\"\n",
    "call_conversational_rag(question, final_chain, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3561185-0c75-437e-800c-d46665ba2c75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': \"Baker Mayfield's average number of points per game (PPG) over his last three games is 22.9.\\nJoe Flacco's average number of points per game (PPG) over his last three games is 20.6.\",\n",
       " 'question': 'What is the average number of points per game (PPG) for both Baker Mayfield and Joe Flacco?',\n",
       " 'context': '**Patrick Mahomes (QB – KC)| Panic Meter: 3 **\\n\\nSooner or later the Chiefs have to figure it out, right? We’ve been asking\\nourselves this question for 8 weeks now and nothing has changed. In week 16,\\nMahomes finished with less than 17 points for the seventh time in his last\\neight games. He is QB10 on the season. No QB will offer you the same upside as\\nMahomes, but there are several likely-available players that have displayed a\\nmuch higher floor as of late. Consider these options:\\n\\n  * Baker Mayfield\\n\\n(QB – TB): averaging 22.9 PPG over his last three games.\\n\\n  * Joe Flacco\\n\\n(QB – CLE): averaging 351 pass YPG and 20.6 PPG over his last three games.\\n\\n**Austin Ekeler (RB – LAC) | Panic Meter: 3**\\n\\n## League Standings\\n\\n-\\n\\nLeague Standings\\n\\n-\\n\\nPower Rankings\\n\\nPlayoff  \\nOdds\\n\\n## League Matchup\\n\\nMy Team\\n\\n## \\\\--\\n\\n\\\\--\\n\\n\\\\- %\\n\\nvs\\n\\nOpponent\\n\\n## \\\\--\\n\\n\\\\--\\n\\n\\\\- %\\n\\n## Roster Tools\\n\\nStart/Sit\\n\\nWaiver\\n\\nTrade\\n\\n## Power Rankings\\n\\n## Power Rankings\\n\\nCreated with Highcharts 6.2.0QBRBWRTEKDEF6\\n\\n## Auto Pilot\\n\\n## Auto-Pilot\\n\\nAutomatically swap inactive players out of your lineup on .\\n\\nOn __ Off\\n\\nConfigure\\n\\n## Player Rankings\\n\\n## Player Rankings\\n\\n  * Weekly Rankings\\n\\nView\\n\\n  * Rest of Season Rankings\\n\\nView\\n\\n  * FantasyPros Expert Rankings\\n\\nView\\n\\n  * Waiver Wire Rankings\\n\\nView\\n\\n  * Dynasty Rankings\\n\\nView\\n\\n* NFL Home\\n  * Tools __\\n    *       * In-Season\\n      * My Playbook\\n      * Who Should I Start?\\n      * Start/Sit Assistant\\n      * Auto-Pilot\\n      * Waiver Central\\n      * Waiver Assistant\\n      * Free Agent Finder\\n      * Trade Analyzer\\n      * Trade Central\\n      * Trade Finder\\n      * Multi-League Assistant\\n      * Game Day\\n    *       * Draft\\n      * Draft Simulator\\n      * Mock Draft Lobby\\n      * Live Draft Assistant\\n      * Draft Kit\\n      * Perfect Draft Challenge\\n      * Cheat Sheet Creator\\n      * Salary Cap Simulator\\n      * Salary Cap Calculator\\n      * Draft Analyzer\\n      * QBBC Finder\\n      * Draft Order Generator\\n      * Draft Software\\n      * Who Should I Draft?\\n    *       * Sports Betting\\n      * Prop Bet Cheat Sheet\\n      * PrizePicks Cheat Sheet\\n      * Prop Bet Analyzer\\n      * Game Picks\\n      * Bet Dashboard\\n      * Live Odds\\n      * Mobile App\\n  * Rankings __\\n    *       * Week 17\\n      * Expert Consensus Rankings\\n      * Half PPR Rankings\\n      * PPR Rankings\\n      * Standard Rankings\\n      * IDP Rankings\\n      * FantasyPros Experts\\n      * Waiver Wire\\n      * Expert Directory\\n      * Player Notes\\n    *       * Rest of Season\\n      * Expert Consensus Rankings\\n      * Half PPR Rankings\\n      * PPR Rankings\\n      * Standard Rankings\\n      * Player Notes\\n      * Expert Directory\\n    *       * Dynasty\\n      * Expert Consensus Rankings\\n      * Rookie Rankings\\n      * Trade Value Chart\\n      * Prospect Rankings\\n      * IDP Rankings\\n      * FantasyPros Experts\\n      * Expert Directory\\n  * Projections __\\n    * Week 17\\n    * Full Season\\n  * Start or Sit __\\n    * Who Should I Start?\\n    * Start/Sit Assistant\\n    * Multi-League Assistant\\n    * Start/Sit Articles\\n  * Waiver Wire __\\n    * Waiver Wire Articles\\n    * Waiver Wire Central\\n    * Waiver Wire Assistant\\n    * Rest of Season Rankings\\n    * Waiver Wire Rankings\\n    * Free Agent Finder\\n    * Strength of Schedule\\n    * Matchup Calendar\\n    * Depth Charts\\n    * Bye Week Cheat Sheet\\n  * Stats __\\n    * Fantasy Football Stats\\n    * Most Targeted Players\\n    * NFL Snap Count Leaders\\n    * NFL Red Zone Stats\\n    * Advanced Quarterback Stats\\n    * Advanced Running Back Stats\\n    * Advanced Wide Receiver Stats\\n    * Advanced Tight End Stats\\n    * Fantasy Points Allowed\\n  * Research __\\n    *       * Research\\n      * 2023 Projections\\n      * Weekly Projections\\n      * Projected Leaders\\n      * Betting Odds\\n      * Prop Bet Cheat Sheet\\n      * Prop Bet Analyzer\\n      * Bet Dashboard\\n      * Game Picks\\n      * Inactives List\\n      * Injuries\\n      * Player Insights\\n      * Strategy Tips\\n      * Dynasty Draft Kit\\n      * Average Draft Position\\n      * Best Ball Draft Kit\\n      * Sleeper Rankings\\n    *       * Reports\\n      * Fantasy Leaders\\n      * Stats Leaders\\n      * Points Distribution\\n      * Target Leaders\\n      * Targets by Team\\n      * Snap Count Leaders\\n      * Snap Count Analysis\\n      * Fantasy Depth Charts\\n      * RB Handcuffs\\n      * Fantasy Points Allowed\\n      * Red Zone Stats\\n      * Advanced Stats\\n      * Value Based Drafting\\n      * Boom Bust Report\\n      * Touchdown Regression\\n      * Free Agency Tracker\\n    *       * Schedules\\n      * 2023 NFL Schedule\\n      * Strength of Schedule\\n      * Matchup Calendar\\n      * Bye Week Cheat Sheet\\n      * Bye Weeks by Team\\n    *       * Experts\\n      * In-Season Accuracy\\n      * Draft Accuracy\\n      * DFS Accuracy\\n      * Videos\\n      * Consensus Sleepers\\n      * Consensus Busts\\n      * Dissenting Opinions\\n      * Expert Directory\\n  * Articles __\\n    * Sleepers\\n    * Busts\\n    * Dynasty\\n    * Strategy\\n    * Trade Advice\\n    * Daily Fantasy\\n  * News __\\n    *       * Player Updates\\n      * All News\\n      * Breaking\\n      * Rumors\\n      * Injuries\\n      * Transactions\\n      * NFL Draft\\n    *       * Featured\\n      * Injuries\\n      * Sleepers\\n      * Busts\\n      * Strategy\\n      * Start/Sit\\n      * Waiver Wire\\n      * Rankings\\n      * Dynasty\\n      * Player Profiles\\n      * Rookies\\n      * Partner Articles\\n      * Podcasts\\n      * Videos\\n  * Podcast __\\n    * Fantasy Football\\n    * Dynasty Football\\n    * Game Changers\\n    * The Kickoff\\n    * Promo Codes\\n  * Apps\\n\\n1. NHL Prop Bet Cheat Sheet\\n\\nDec 22 — BettingPros\\n\\n1\\n\\n  2. The NBA PrizePicks Cheat Sheet Has Arrived!\\n\\nDec 01 — BettingPros\\n\\n2\\n\\n  3. Introducing Waiver Central - the Quickest and Easiest Way to Improve Your Fantasy Team\\n\\nNov 30 — My Playbook\\n\\n3\\n\\n  4. New NFL Touchdown Scorer Reports - Anytime & First TD Prop Bet Analysis\\n\\nOct 25 — BettingPros\\n\\n4\\n\\n  5. Major FantasyPros App Update: Win More, Stress Less\\n\\nOct 09 — FantasyPros.com\\n\\n5\\n\\nMore Updates\\n\\n## Command Center\\n\\n## League Hub Navigation\\n\\nSync your league\\n\\nSync\\n\\n-\\n\\nStandings\\n\\n-\\n\\nRankings\\n\\nPlayoffs\\n\\nStart/Sit\\n\\nWaiver\\n\\nTrade\\n\\nPlayer Rankings\\n\\n## League Hub Console\\n\\n## League Sync\\n\\n### Sync your NFL  \\nleague for FREE!\\n\\nImport your fantasy league and get personalized advice for your team.\\n\\nSync Your League\\n\\nAlready Synced? Sign In'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"How many PPG are both averaging?\"\n",
    "call_conversational_rag(question, final_chain, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a7b807a-319c-40be-b198-cd0c3d947f02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'The original quarterback mentioned in the conversation was Patrick Mahomes.',\n",
       " 'question': 'Who was the original quarterback mentioned in the conversation?',\n",
       " 'context': '|\\n\\n2 min read\\n\\nNext Up - **Fantasy Football NFL Week 17 Injury Report & Outlook (2023)**\\n\\nNext Article  \\n\\nThis website uses cookies to provide basic functionality, enhance user\\nexperience, and to analyze performance and traffic. We also share information\\nabout your use of our site with our social media, advertising, and analytics\\npartners.  \\n  \\nBy using this website you agree to our Terms of Use.\\n\\nDo Not Sell My Personal Information Accept Cookies\\n\\n__ Follow\\n\\n## More Articles\\n\\n### Fantasy Football NFL Week 17 Injury Report & Outlook (2023)\\n\\nby **Deepak Chona - MD** | 2 min read\\n\\n### Fantasy Football Week 17 Rankings, Grades & Start/Sit Advice (2023)\\n\\nby **FantasyPros Staff** | 15+ min read\\n\\n### NFL DFS Week 17 Stacking Advice & Picks (2023 Fantasy Football)\\n\\nby **Joe Pepe** | 1 min read\\n\\n### Last-Minute Fantasy Football Advice for Week 17 (2023)\\n\\nby **FantasyPros Staff** | 2 min read\\n\\n# About Author\\n\\nTim Brosnan\\n\\nTim Brosnan is a featured writer at FantasyPros, providing unique insights and\\nin-depth analysis.\\n\\n# Recent Articles\\n\\nFantasy Football NFL Week 17 Injury Report & Outlook (2023)\\n\\n14h ago\\n\\nFantasy Football Week 17 Rankings, Grades & Start/Sit Advice (2023)\\n\\n14h ago\\n\\n#  Fantasy Football Panic Meter: Patrick Mahomes, Austin Ekeler, Stefon Diggs,\\nTravis Etienne\\n\\nby  Tim Brosnan  |  Dec 26, 2023\\n\\nWe currently live in a world where you can’t trust (spoiler alert) Patrick\\nMahomes\\n\\n, Austin Ekeler\\n\\nor Stefon Diggs\\n\\nin your starting lineup. Up is down, hot is cold, Joe Flacco\\n\\nis in MVP-form and we’re all just trying to piece things together.\\n\\nThis week, on a special edition of ‘The Panic Meter’ we will feature several\\nplayers you should be panicked enough to avoid starting, as well as\\nstreaming/bench alternatives to replace them.\\n\\nIf you’ve made it this far, congratulations. If you fell short, you probably\\nhave a player on this list.\\n\\nWithout further ado, here is this week’s fantasy football panic meter.\\n\\nNFL DFS Week 17 Stacking Advice & Picks (2023 Fantasy Football)\\n\\n18h ago\\n\\nLast-Minute Fantasy Football Advice for Week 17 (2023)\\n\\n21h ago\\n\\nNFL DFS Cheat Sheet: Picks for Every Game (Week 17)\\n\\n21h ago\\n\\n6 Last-Minute Fantasy Football Waiver Wire Pickups & Injury Replacements (Week\\n17)\\n\\n21h ago\\n\\nFantasy Football Hot Takes: Cole Kmet, Puka Nacua, Joe Mixon, Jaren Hall (Week\\n17)\\n\\n21h ago\\n\\n# Go Premium For FREE\\n\\nMake a minimum deposit with a partner and get up to a 1-Year Subscription for\\nFREE. Paid entry at select sites required.\\n\\nClaim Offer\\n\\n# Player News\\n\\n  * NFL\\n  * MLB\\n  * NBA\\n  * NHL\\n\\nKenneth Walker III\\n\\n(shoulder/illness) considered game-time decision Sunday\\n\\nJacoby Brissett\\n\\n(hamstring) shaping up to be game-time decision Sunday\\n\\nDK Metcalf\\n\\n(back) listed questionable for Week 17'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Who did I originally ask about?\"\n",
    "call_conversational_rag(question, final_chain, memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac130f9-a8d3-443d-8d5b-0744d29a5bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
