{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca0c2ec-cd58-415f-a71e-c024ac554306",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88d20621-b3b9-438e-b31e-058c9cc7ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-29 16:45:03.574276: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-29 16:45:03.631987: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import GenerationConfig\n",
    "import transformers\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056255e-c817-47be-adaa-f2bc21daa282",
   "metadata": {},
   "source": [
    "### Load and test out mistral-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c3be99-c274-438a-8041-b1df8129c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3380ad2c-6910-4926-b528-3230ef4a3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# QLoRA parameters\n",
    "################################################################################\n",
    "\n",
    "# LoRA attention dimension\n",
    "lora_r = 64\n",
    "\n",
    "# Alpha parameter for LoRA scaling\n",
    "lora_alpha = 16\n",
    "\n",
    "# Dropout probability for LoRA layers\n",
    "lora_dropout = 0.1\n",
    "\n",
    "################################################################################\n",
    "# bitsandbytes parameters\n",
    "################################################################################\n",
    "\n",
    "# Activate 4-bit precision base model loading\n",
    "use_4bit = True\n",
    "\n",
    "# Compute dtype for 4-bit base models\n",
    "bnb_4bit_compute_dtype = \"float16\"\n",
    "\n",
    "# Quantization type (fp4 or nf4)\n",
    "bnb_4bit_quant_type = \"nf4\"\n",
    "\n",
    "# Activate nested quantization for 4-bit base models (double quantization)\n",
    "use_nested_quant = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b63e06c-8f91-4792-b953-a89d03fef375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer and model with QLoRA configuration\n",
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type,\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=use_nested_quant,\n",
    ")\n",
    "\n",
    "# Check GPU compatibility with bfloat16\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc6476e-81e5-4dff-b5be-ccc1bbec90b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                                  Version\n",
      "---------------------------------------- ---------------\n",
      "absl-py                                  1.4.0\n",
      "accelerate                               0.21.0\n",
      "aiohttp                                  3.8.5\n",
      "aiohttp-cors                             0.7.0\n",
      "aiorwlock                                1.3.0\n",
      "aiosignal                                1.3.1\n",
      "ansiwrap                                 0.8.4\n",
      "anyio                                    3.7.1\n",
      "apache-beam                              2.46.0\n",
      "argon2-cffi                              21.3.0\n",
      "argon2-cffi-bindings                     21.2.0\n",
      "array-record                             0.4.1\n",
      "arrow                                    1.2.3\n",
      "asttokens                                2.2.1\n",
      "astunparse                               1.6.3\n",
      "async-lru                                2.0.4\n",
      "async-timeout                            4.0.3\n",
      "attrs                                    23.1.0\n",
      "Babel                                    2.12.1\n",
      "backcall                                 0.2.0\n",
      "backoff                                  2.2.1\n",
      "backports.functools-lru-cache            1.6.5\n",
      "beatrix-jupyterlab                       2023.814.150030\n",
      "beautifulsoup4                           4.12.2\n",
      "bitsandbytes                             0.40.2\n",
      "bleach                                   6.0.0\n",
      "blessed                                  1.20.0\n",
      "boltons                                  23.0.0\n",
      "Brotli                                   1.0.9\n",
      "brotlipy                                 0.7.0\n",
      "cached-property                          1.5.2\n",
      "cachetools                               4.2.4\n",
      "certifi                                  2023.7.22\n",
      "cffi                                     1.15.1\n",
      "chardet                                  5.2.0\n",
      "charset-normalizer                       3.2.0\n",
      "click                                    8.1.7\n",
      "cloud-tpu-client                         0.10\n",
      "cloud-tpu-profiler                       2.4.0\n",
      "cloudpickle                              2.2.1\n",
      "cmake                                    3.27.5\n",
      "colorama                                 0.4.6\n",
      "colorful                                 0.5.5\n",
      "comm                                     0.1.4\n",
      "conda                                    23.7.3\n",
      "conda-package-handling                   2.2.0\n",
      "conda_package_streaming                  0.9.0\n",
      "contourpy                                1.1.0\n",
      "crcmod                                   1.7\n",
      "cryptography                             41.0.3\n",
      "cycler                                   0.11.0\n",
      "Cython                                   3.0.0\n",
      "dacite                                   1.8.1\n",
      "dataclasses-json                         0.6.1\n",
      "datasets                                 2.14.5\n",
      "db-dtypes                                1.1.1\n",
      "debugpy                                  1.6.7.post1\n",
      "decorator                                5.1.1\n",
      "defusedxml                               0.7.1\n",
      "Deprecated                               1.2.14\n",
      "dill                                     0.3.7\n",
      "distlib                                  0.3.7\n",
      "dm-tree                                  0.1.8\n",
      "docker                                   6.1.3\n",
      "docopt                                   0.6.2\n",
      "docstring-parser                         0.15\n",
      "emoji                                    2.8.0\n",
      "entrypoints                              0.4\n",
      "etils                                    1.4.1\n",
      "exceptiongroup                           1.1.3\n",
      "executing                                1.2.0\n",
      "explainable-ai-sdk                       1.3.3\n",
      "faiss-gpu                                1.7.2\n",
      "fastapi                                  0.101.1\n",
      "fastavro                                 1.8.2\n",
      "fasteners                                0.18\n",
      "fastjsonschema                           2.18.0\n",
      "filelock                                 3.12.2\n",
      "filetype                                 1.2.0\n",
      "flatbuffers                              23.5.26\n",
      "flit_core                                3.9.0\n",
      "fonttools                                4.42.1\n",
      "fqdn                                     1.5.1\n",
      "frozenlist                               1.4.0\n",
      "fsspec                                   2023.6.0\n",
      "gast                                     0.4.0\n",
      "gcsfs                                    2023.6.0\n",
      "gitdb                                    4.0.10\n",
      "GitPython                                3.1.32\n",
      "google-api-core                          1.34.0\n",
      "google-api-python-client                 1.8.0\n",
      "google-apitools                          0.5.31\n",
      "google-auth                              2.22.0\n",
      "google-auth-httplib2                     0.1.0\n",
      "google-auth-oauthlib                     1.0.0\n",
      "google-cloud-aiplatform                  1.31.0\n",
      "google-cloud-artifact-registry           1.8.3\n",
      "google-cloud-bigquery                    3.11.4\n",
      "google-cloud-bigquery-storage            2.16.2\n",
      "google-cloud-bigtable                    1.7.3\n",
      "google-cloud-core                        2.3.3\n",
      "google-cloud-datastore                   1.15.5\n",
      "google-cloud-dlp                         3.12.2\n",
      "google-cloud-language                    1.3.2\n",
      "google-cloud-monitoring                  2.15.1\n",
      "google-cloud-pubsub                      2.18.3\n",
      "google-cloud-pubsublite                  1.8.3\n",
      "google-cloud-recommendations-ai          0.7.1\n",
      "google-cloud-resource-manager            1.10.3\n",
      "google-cloud-spanner                     3.40.1\n",
      "google-cloud-storage                     2.10.0\n",
      "google-cloud-videointelligence           1.16.3\n",
      "google-cloud-vision                      3.4.4\n",
      "google-crc32c                            1.5.0\n",
      "google-pasta                             0.2.0\n",
      "google-resumable-media                   2.5.0\n",
      "googleapis-common-protos                 1.60.0\n",
      "gpustat                                  1.0.0\n",
      "greenlet                                 2.0.2\n",
      "grpc-google-iam-v1                       0.12.6\n",
      "grpcio                                   1.48.1\n",
      "grpcio-status                            1.48.1\n",
      "gviz-api                                 1.10.0\n",
      "Gymnasium                                0.26.3\n",
      "gymnasium-notices                        0.0.1\n",
      "h11                                      0.14.0\n",
      "h5py                                     3.9.0\n",
      "hdfs                                     2.7.2\n",
      "html2text                                2020.1.16\n",
      "htmlmin                                  0.1.12\n",
      "httplib2                                 0.21.0\n",
      "huggingface-hub                          0.17.3\n",
      "idna                                     3.4\n",
      "ImageHash                                4.3.1\n",
      "imageio                                  2.31.1\n",
      "importlib-metadata                       6.8.0\n",
      "importlib-resources                      6.0.1\n",
      "ipykernel                                6.25.1\n",
      "ipython                                  8.14.0\n",
      "ipython-genutils                         0.2.0\n",
      "ipython-sql                              0.5.0\n",
      "ipywidgets                               8.1.0\n",
      "isoduration                              20.11.0\n",
      "jaraco.classes                           3.3.0\n",
      "jedi                                     0.19.0\n",
      "jeepney                                  0.8.0\n",
      "Jinja2                                   3.1.2\n",
      "joblib                                   1.3.2\n",
      "json5                                    0.9.14\n",
      "jsonpatch                                1.33\n",
      "jsonpointer                              2.0\n",
      "jsonschema                               4.19.0\n",
      "jsonschema-specifications                2023.7.1\n",
      "jupyter_client                           7.4.9\n",
      "jupyter_core                             5.3.1\n",
      "jupyter-events                           0.7.0\n",
      "jupyter-http-over-ws                     0.0.8\n",
      "jupyter-lsp                              2.2.0\n",
      "jupyter-server                           1.24.0\n",
      "jupyter-server-mathjax                   0.2.6\n",
      "jupyter_server_proxy                     4.0.0\n",
      "jupyter_server_terminals                 0.4.4\n",
      "jupyterlab                               3.4.8\n",
      "jupyterlab_git                           0.42.0\n",
      "jupyterlab-pygments                      0.2.2\n",
      "jupyterlab_server                        2.24.0\n",
      "jupyterlab-widgets                       3.0.8\n",
      "jupytext                                 1.15.0\n",
      "keras                                    2.13.1\n",
      "keras-tuner                              1.3.5\n",
      "keyring                                  24.2.0\n",
      "keyrings.google-artifactregistry-auth    1.1.2\n",
      "kfp                                      2.0.1\n",
      "kfp-pipeline-spec                        0.2.2\n",
      "kfp-server-api                           2.0.1\n",
      "kiwisolver                               1.4.4\n",
      "kt-legacy                                1.0.5\n",
      "kubernetes                               26.1.0\n",
      "langchain                                0.0.314\n",
      "langdetect                               1.0.9\n",
      "langsmith                                0.0.43\n",
      "lazy_loader                              0.3\n",
      "libclang                                 16.0.6\n",
      "lit                                      17.0.1\n",
      "llvmlite                                 0.40.1\n",
      "lxml                                     4.9.3\n",
      "lz4                                      4.3.2\n",
      "Markdown                                 3.4.4\n",
      "markdown-it-py                           3.0.0\n",
      "MarkupSafe                               2.0.1\n",
      "marshmallow                              3.20.1\n",
      "matplotlib                               3.7.2\n",
      "matplotlib-inline                        0.1.6\n",
      "mdit-py-plugins                          0.4.0\n",
      "mdurl                                    0.1.2\n",
      "mistune                                  3.0.1\n",
      "more-itertools                           10.1.0\n",
      "mpmath                                   1.3.0\n",
      "msgpack                                  1.0.5\n",
      "multidict                                6.0.4\n",
      "multimethod                              1.9.1\n",
      "multiprocess                             0.70.15\n",
      "mypy-extensions                          1.0.0\n",
      "nb-conda                                 2.2.1\n",
      "nb-conda-kernels                         2.3.1\n",
      "nbclassic                                1.0.0\n",
      "nbclient                                 0.8.0\n",
      "nbconvert                                7.7.4\n",
      "nbdime                                   3.2.0\n",
      "nbformat                                 5.9.2\n",
      "nest-asyncio                             1.5.6\n",
      "networkx                                 3.1\n",
      "nltk                                     3.8.1\n",
      "notebook                                 6.5.5\n",
      "notebook-executor                        0.2\n",
      "notebook_shim                            0.2.3\n",
      "numba                                    0.57.1\n",
      "numpy                                    1.23.5\n",
      "nvidia-cublas-cu11                       11.10.3.66\n",
      "nvidia-cublas-cu12                       12.1.3.1\n",
      "nvidia-cuda-cupti-cu11                   11.7.101\n",
      "nvidia-cuda-cupti-cu12                   12.1.105\n",
      "nvidia-cuda-nvrtc-cu11                   11.7.99\n",
      "nvidia-cuda-nvrtc-cu12                   12.1.105\n",
      "nvidia-cuda-runtime-cu11                 11.7.99\n",
      "nvidia-cuda-runtime-cu12                 12.1.105\n",
      "nvidia-cudnn-cu11                        8.5.0.96\n",
      "nvidia-cudnn-cu12                        8.9.2.26\n",
      "nvidia-cufft-cu11                        10.9.0.58\n",
      "nvidia-cufft-cu12                        11.0.2.54\n",
      "nvidia-curand-cu11                       10.2.10.91\n",
      "nvidia-curand-cu12                       10.3.2.106\n",
      "nvidia-cusolver-cu11                     11.4.0.1\n",
      "nvidia-cusolver-cu12                     11.4.5.107\n",
      "nvidia-cusparse-cu11                     11.7.4.91\n",
      "nvidia-cusparse-cu12                     12.1.0.106\n",
      "nvidia-ml-py                             11.495.46\n",
      "nvidia-nccl-cu11                         2.14.3\n",
      "nvidia-nccl-cu12                         2.18.1\n",
      "nvidia-nvjitlink-cu12                    12.2.140\n",
      "nvidia-nvtx-cu11                         11.7.91\n",
      "nvidia-nvtx-cu12                         12.1.105\n",
      "oauth2client                             4.1.3\n",
      "oauthlib                                 3.2.2\n",
      "objsize                                  0.6.1\n",
      "openai                                   0.28.1\n",
      "opencensus                               0.11.2\n",
      "opencensus-context                       0.1.3\n",
      "opentelemetry-api                        1.19.0\n",
      "opentelemetry-exporter-otlp              1.19.0\n",
      "opentelemetry-exporter-otlp-proto-common 1.19.0\n",
      "opentelemetry-exporter-otlp-proto-grpc   1.19.0\n",
      "opentelemetry-exporter-otlp-proto-http   1.19.0\n",
      "opentelemetry-proto                      1.19.0\n",
      "opentelemetry-sdk                        1.19.0\n",
      "opentelemetry-semantic-conventions       0.40b0\n",
      "opt-einsum                               3.3.0\n",
      "orjson                                   3.9.5\n",
      "outcome                                  1.2.0\n",
      "overrides                                6.5.0\n",
      "packaging                                23.1\n",
      "pandas                                   2.0.3\n",
      "pandas-profiling                         3.6.6\n",
      "pandocfilters                            1.5.0\n",
      "papermill                                2.4.0\n",
      "parso                                    0.8.3\n",
      "patsy                                    0.5.3\n",
      "peft                                     0.4.0\n",
      "pexpect                                  4.8.0\n",
      "phik                                     0.12.3\n",
      "pickleshare                              0.7.5\n",
      "Pillow                                   10.0.0\n",
      "pip                                      23.2.1\n",
      "pkgutil_resolve_name                     1.3.10\n",
      "platformdirs                             3.10.0\n",
      "playwright                               1.38.0\n",
      "plotly                                   5.16.1\n",
      "pluggy                                   1.2.0\n",
      "prettytable                              3.8.0\n",
      "prometheus-client                        0.17.1\n",
      "promise                                  2.3\n",
      "prompt-toolkit                           3.0.39\n",
      "proto-plus                               1.22.3\n",
      "protobuf                                 3.20.3\n",
      "psutil                                   5.9.3\n",
      "ptyprocess                               0.7.0\n",
      "pure-eval                                0.2.2\n",
      "py-spy                                   0.3.14\n",
      "pyarrow                                  9.0.0\n",
      "pyasn1                                   0.4.8\n",
      "pyasn1-modules                           0.2.7\n",
      "pycosat                                  0.6.4\n",
      "pycparser                                2.21\n",
      "pydantic                                 1.10.12\n",
      "pydot                                    1.4.2\n",
      "pyee                                     9.0.4\n",
      "Pygments                                 2.16.1\n",
      "PyJWT                                    2.8.0\n",
      "pymongo                                  3.13.0\n",
      "pyOpenSSL                                23.2.0\n",
      "pyparsing                                3.0.9\n",
      "PySocks                                  1.7.1\n",
      "python-dateutil                          2.8.2\n",
      "python-iso639                            2023.6.15\n",
      "python-json-logger                       2.0.7\n",
      "python-magic                             0.4.27\n",
      "pytz                                     2023.3\n",
      "pyu2f                                    0.1.5\n",
      "PyWavelets                               1.4.1\n",
      "PyYAML                                   6.0.1\n",
      "pyzmq                                    24.0.1\n",
      "rapidfuzz                                3.4.0\n",
      "ray                                      2.6.3\n",
      "ray-cpp                                  2.6.3\n",
      "referencing                              0.30.2\n",
      "regex                                    2023.8.8\n",
      "requests                                 2.31.0\n",
      "requests-oauthlib                        1.3.1\n",
      "requests-toolbelt                        0.10.1\n",
      "retrying                                 1.3.3\n",
      "rfc3339-validator                        0.1.4\n",
      "rfc3986-validator                        0.1.1\n",
      "rich                                     13.5.2\n",
      "rpds-py                                  0.9.2\n",
      "rsa                                      4.9\n",
      "ruamel.yaml                              0.17.32\n",
      "ruamel.yaml.clib                         0.2.7\n",
      "safetensors                              0.3.3\n",
      "scikit-image                             0.21.0\n",
      "scikit-learn                             1.3.0\n",
      "scipy                                    1.11.2\n",
      "seaborn                                  0.12.2\n",
      "SecretStorage                            3.3.3\n",
      "selenium                                 4.14.0\n",
      "Send2Trash                               1.8.2\n",
      "sentence-transformers                    2.2.2\n",
      "sentencepiece                            0.1.99\n",
      "setuptools                               68.1.2\n",
      "Shapely                                  1.8.5.post1\n",
      "simpervisor                              1.0.0\n",
      "six                                      1.16.0\n",
      "smart-open                               6.3.0\n",
      "smmap                                    5.0.0\n",
      "sniffio                                  1.3.0\n",
      "sortedcontainers                         2.4.0\n",
      "soupsieve                                2.3.2.post1\n",
      "SQLAlchemy                               2.0.20\n",
      "sqlparse                                 0.4.4\n",
      "stack-data                               0.6.2\n",
      "starlette                                0.27.0\n",
      "statsmodels                              0.14.0\n",
      "sympy                                    1.12\n",
      "tabulate                                 0.9.0\n",
      "tangled-up-in-unicode                    0.2.0\n",
      "tenacity                                 8.2.3\n",
      "tensorboard                              2.13.0\n",
      "tensorboard-data-server                  0.7.1\n",
      "tensorboard-plugin-profile               2.13.1\n",
      "tensorboardX                             2.6.2.2\n",
      "tensorflow                               2.13.0\n",
      "tensorflow-cloud                         0.1.16\n",
      "tensorflow-datasets                      4.9.2\n",
      "tensorflow-estimator                     2.13.0\n",
      "tensorflow-hub                           0.14.0\n",
      "tensorflow-io                            0.32.0\n",
      "tensorflow-io-gcs-filesystem             0.32.0\n",
      "tensorflow-metadata                      0.14.0\n",
      "tensorflow-probability                   0.21.0\n",
      "tensorflow-serving-api                   2.13.0\n",
      "tensorflow-transform                     0.14.0\n",
      "termcolor                                2.3.0\n",
      "terminado                                0.17.1\n",
      "textwrap3                                0.9.2\n",
      "threadpoolctl                            3.2.0\n",
      "tifffile                                 2023.8.12\n",
      "tiktoken                                 0.5.1\n",
      "tinycss2                                 1.2.1\n",
      "tokenizers                               0.15.0\n",
      "toml                                     0.10.2\n",
      "tomli                                    2.0.1\n",
      "toolz                                    0.12.0\n",
      "torch                                    2.1.0\n",
      "torchvision                              0.16.0\n",
      "tornado                                  6.3.3\n",
      "tqdm                                     4.66.1\n",
      "traitlets                                5.9.0\n",
      "transformers                             4.35.2\n",
      "trio                                     0.22.2\n",
      "trio-websocket                           0.11.1\n",
      "triton                                   2.1.0\n",
      "trl                                      0.4.7\n",
      "typeguard                                2.13.3\n",
      "typer                                    0.9.0\n",
      "typing_extensions                        4.5.0\n",
      "typing-inspect                           0.9.0\n",
      "typing-utils                             0.1.0\n",
      "tzdata                                   2023.3\n",
      "unstructured                             0.10.22\n",
      "uri-template                             1.3.0\n",
      "uritemplate                              3.0.1\n",
      "urllib3                                  1.26.15\n",
      "uvicorn                                  0.23.2\n",
      "virtualenv                               20.21.0\n",
      "visions                                  0.7.5\n",
      "wcwidth                                  0.2.6\n",
      "webcolors                                1.13\n",
      "webencodings                             0.5.1\n",
      "websocket-client                         1.6.2\n",
      "Werkzeug                                 2.1.2\n",
      "wheel                                    0.41.2\n",
      "widgetsnbextension                       4.0.8\n",
      "witwidget                                1.8.1\n",
      "wordcloud                                1.9.2\n",
      "wrapt                                    1.15.0\n",
      "wsproto                                  1.2.0\n",
      "xxhash                                   3.3.0\n",
      "yarl                                     1.9.2\n",
      "ydata-profiling                          4.5.1\n",
      "zipp                                     3.16.2\n",
      "zstandard                                0.19.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fee206e-cc5a-4d8a-b1d6-27007e99425f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d130e07ca94f4f0797a5b6d7a32fd98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    572\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3480\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3472\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[1;32m   3473\u001b[0m     (\n\u001b[1;32m   3474\u001b[0m         model,\n\u001b[1;32m   3475\u001b[0m         missing_keys,\n\u001b[1;32m   3476\u001b[0m         unexpected_keys,\n\u001b[1;32m   3477\u001b[0m         mismatched_keys,\n\u001b[1;32m   3478\u001b[0m         offload_index,\n\u001b[1;32m   3479\u001b[0m         error_msgs,\n\u001b[0;32m-> 3480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3491\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3492\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3498\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[1;32m   3499\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3856\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[0;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[1;32m   3854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shard_file \u001b[38;5;129;01min\u001b[39;00m disk_only_shard_files:\n\u001b[1;32m   3855\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m-> 3856\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshard_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3858\u001b[0m \u001b[38;5;66;03m# Mistmatched keys contains tuples key/shape1/shape2 of weights in the checkpoint that have a shape not\u001b[39;00m\n\u001b[1;32m   3859\u001b[0m \u001b[38;5;66;03m# matching the weights in the model.\u001b[39;00m\n\u001b[1;32m   3860\u001b[0m mismatched_keys \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m _find_mismatched_keys(\n\u001b[1;32m   3861\u001b[0m     state_dict,\n\u001b[1;32m   3862\u001b[0m     model_state_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3866\u001b[0m     ignore_mismatched_sizes,\n\u001b[1;32m   3867\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:484\u001b[0m, in \u001b[0;36mload_state_dict\u001b[0;34m(checkpoint_file)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m         map_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1392\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1391\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1392\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:1357\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1357\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a57c26ff-cbf1-4e91-a171-ffb7d14899bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable model parameters: 262410240\n",
      "all model parameters: 3752071168\n",
      "percentage of trainable model parameters: 6.99%\n"
     ]
    }
   ],
   "source": [
    "def print_number_of_trainable_model_parameters(model):\n",
    "    trainable_model_params = 0\n",
    "    all_model_params = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_model_params += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_model_params += param.numel()\n",
    "    return f\"trainable model parameters: {trainable_model_params}\\nall model parameters: {all_model_params}\\npercentage of trainable model parameters: {100 * trainable_model_params / all_model_params:.2f}%\"\n",
    "\n",
    "print(print_number_of_trainable_model_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91d75a12-ccee-4eb9-afd9-fe856d7dc7b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] What can you tell me about the 2021 fantasy football season? [/INST]The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
      "\n",
      "    Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
      "\n",
      "    In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
      "\n",
      "    As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
      "\n",
      "    * Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
      "    * Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
      "    * Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
      "    * Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
      "\n",
      "    In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.</s>  [INST] How many points did Maholmes score that season? [/INST]Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.</s>  [INST] Can you tell me how many points he scored in week 3 of that season? [/INST]Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.</s>  [INST] Did anyone score more than him in that week? [/INST]As of my knowledge up to August 2022, Patrick Mahomes scored the most points among quarterbacks in week 3 of the 2021 fantasy football regular season. However, it's worth noting that fantasy football points are calculated based on various factors, including yardage, touchdowns, and other statistics, and the final point totals for a given week can vary depending on how those factors are weighted and how they contribute to a team's overall performance.</s>\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What can you tell me about the 2021 fantasy football season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"\"The 2021 fantasy football season began on August 17th, 2021, with the first games of the NFL Preseason. The regular season started on September 11th, 2021 and ended on January 9th, 2022. The Super Bowl LVI, which was the 56th Super Bowl, was held on February 6th, 2022, at SoFi Stadium in Los Angeles, California.\n",
    "\n",
    "    Due to the COVID-19 pandemic, the 2021 fantasy football season was played with some changes, including a reduced preseason schedule, the elimination of in-person attendance at games, and the use of virtual meetings for teams.\n",
    "\n",
    "    In terms of fantasy football leagues, many leagues opted to use a PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards. The use of PPR has become increasingly popular in recent years, as it provides more opportunities for players to score points.\n",
    "\n",
    "    As for notable players in the 2021 fantasy football season, some of the top performers included:\n",
    "\n",
    "    * Quarterbacks: Patrick Mahomes of the Kansas City Chiefs, Justin Herbert of the Los Angeles Chargers, and Tom Brady of the Tampa Bay Buccaneers.\n",
    "    * Running Backs: Christian McCaffery of the Carolina Panthers, Alvin Kamara of the New Orleans Saints, and Dalvin Cook of the Minnesota Vikings.\n",
    "    * Wide Receivers: Tyreek Hill of the Kansas City Chiefs, Stefon Diggs of the Buffalo Bills, and DeAndre Hopkins of the Arizona Cardinals.\n",
    "    * Tight Ends: Travis Kelce of the Kansas City Chiefs, George Kittle of the San Francisco 49ers, and Tyler Higbee of the Los Angeles Rams.\n",
    "\n",
    "    In terms of team performance, the Tampa Bay Buccaneers won the Super Bowl LVI, defeating the Kansas City Chiefs 31-9. The Green Bay Packers finished the regular season with the best record (13-3), but were eliminated in the divisional round of the playoffs by the Los Angeles Rams. The Oakland Raiders, who moved to Las Vegas in 2020, had a strong season, finishing with a record of 10-6 and making it to the playoffs for the first time since 2016.\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": \"How many points did Maholmes score that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes, the quarterback for the Kansas City Chiefs, scored a total of 456 points in the regular season of the 2021 fantasy football season. This made him the top scoring quarterback in the PPR (Point Pertinent) format, which rewards players for receiving passing yards in addition to rushing yards.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you tell me how many points he scored in week 3 of that season?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Patrick Mahomes scored 35 points in week 3 of the 2021 fantasy football season. This was a strong performance, as Mahomes completed 18 of 29 passes for 283 yards and three touchdowns in a win over the Indianapolis Colts.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Did anyone score more than him in that week?\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, return_tensors=\"pt\")\n",
    "\n",
    "model_inputs = encodeds.to(device)\n",
    "model\n",
    "\n",
    "generated_ids = model.generate(model_inputs, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b7c55d-26e2-43ed-982e-e10776b028b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> [INST] Tell me about fantasy football? [/INST] Fantasy football is a sport in which players create teams of imaginary players and play against each other in a competition. The players are chosen from real-life professional football teams and are given various attributes such as points scored, yards gained, and receptions. Each player has a set number of points that they can earn based on their performance in games.\n",
      "\n",
      "The players on a fantasy football team are chosen based on their perceived potential for success in the real world. For example, if a player is known to be a powerful running back or a skilled receiver, they would be a valuable addition to a fantasy football team.\n",
      "\n",
      "The game is typically played over the course of a season, with each week's games determining the points earned by each player on each team. At the end of the season, the team with the most points wins the championship.\n",
      "\n",
      "Fantasy football has become increasingly popular in recent years, with millions of people playing the game each week. It is a fun and engaging way to follow the real-time action of professional football, and many people find that it adds an extra level of excitement and excitement to the sport.</s>\n"
     ]
    }
   ],
   "source": [
    "inputs_not_chat = tokenizer.encode_plus(\"[INST] Tell me about fantasy football? [/INST]\", return_tensors=\"pt\")['input_ids'].to(device)\n",
    "\n",
    "generated_ids = model.generate(inputs_not_chat, max_new_tokens=1000, do_sample=True)\n",
    "decoded = tokenizer.batch_decode(generated_ids)\n",
    "print(decoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04528bc9-a21c-44e0-a89e-6adf7e27cfae",
   "metadata": {},
   "source": [
    "### RAG RAG RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adc9b45f-91f0-4340-b411-61a2ba6fc498",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74c55b2-9f12-44ef-891e-c4cbca5dec13",
   "metadata": {},
   "source": [
    "Example ChatPromptTemplate\n",
    "\n",
    "```python\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"),\n",
    "    (\"human\", \"{user_input}\"),\n",
    "])\n",
    "\n",
    "messages = template.format_messages(\n",
    "    name=\"Bob\",\n",
    "    user_input=\"What is your name?\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fbcc6409-d423-4699-804a-72341332efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_generation_pipeline = transformers.pipeline(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.2,\n",
    "    repetition_penalty=1.1,\n",
    "    return_full_text=True,\n",
    "    max_new_tokens=300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4865d5fa-dae3-41fb-81d2-5659e631cd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5654ae72-31a9-4c54-84cc-9cc3e5e4864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "### [INST] Instruction: Answer the question based on your fantasy football knowledge. Here is context to help:\n",
    "\n",
    "{context}\n",
    "\n",
    "### QUESTION:\n",
    "{question} [/INST]\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95c95f07-2802-4cda-ba5e-06b16a9592c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prompt from prompt template \n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain = LLMChain(llm=mistral_llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "995e4561-2139-4424-b959-635be93e1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader, UnstructuredURLLoader, PlaywrightURLLoader\n",
    "from langchain.document_loaders.blob_loaders.schema import Blob\n",
    "from langchain.document_loaders.parsers.txt import TextParser\n",
    "from langchain.document_loaders.url_selenium import SeleniumURLLoader\n",
    "from langchain.document_transformers import Html2TextTransformer\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "00665637-892a-4f91-ab45-302a119a07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_document = \"\"\"\n",
    "ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\n",
    "\n",
    "Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\n",
    "\n",
    "Veteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\n",
    "\n",
    "Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\n",
    "\n",
    "\"He's right where I thought he would be, he's right where he should be coming along at at this time,\" Scottie Montgomery said.\n",
    "\n",
    "\"We don't judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that's a really, really good tool.\"\n",
    "\n",
    "Meanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit's fourth-leading tackler.\n",
    "\n",
    "Rookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday's practice. He said it likely stemmed from Sunday's win over Carolina, and he intends to play Sunday.\n",
    "\n",
    "\"It's football, things happen, we certainly work our bodies pretty hard so I'm feeling a lot better today,\" LaPorta said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "81769cb4-2ba8-44ea-9fd3-ce6d24be6067",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = TextParser().parse(Blob(data=test_document))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a859fbf6-9c34-46e0-8dcc-8b1099771752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 258, which is longer than the specified 100\n",
      "Created a chunk of size 233, which is longer than the specified 100\n",
      "Created a chunk of size 158, which is longer than the specified 100\n",
      "Created a chunk of size 126, which is longer than the specified 100\n",
      "Created a chunk of size 307, which is longer than the specified 100\n",
      "Created a chunk of size 286, which is longer than the specified 100\n",
      "Created a chunk of size 220, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db = FAISS.from_documents(documents, HuggingFaceEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e49383a-4cd9-41cd-b5e2-f5053ed15eb8",
   "metadata": {},
   "source": [
    "```python\n",
    "HuggingFaceEmbeddings(\n",
    "    *,\n",
    "    client: Any = None,\n",
    "    model_name: str = 'sentence-transformers/all-mpnet-base-v2',\n",
    "    cache_folder: Optional[str] = None,\n",
    "    model_kwargs: Dict[str, Any] = None,\n",
    "    encode_kwargs: Dict[str, Any] = None,\n",
    "    multi_process: bool = False,\n",
    ") -> None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50e90fe7-589a-410e-90be-4e2ccf5003c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72927abd-3a71-4f3b-8eed-89bb8719ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"ALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\", metadata={'source': None}),\n",
       " Document(page_content=\"Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\", metadata={'source': None}),\n",
       " Document(page_content=\"Gibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\", metadata={'source': None}),\n",
       " Document(page_content='\"He\\'s right where I thought he would be, he\\'s right where he should be coming along at at this time,\" Scottie Montgomery said.', metadata={'source': None})]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"who is gibbs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d7e5e98-0ef3-4818-b9bb-3cfdedba351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d468cb09-607d-4d1e-b600-79bebbfad736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"It's football, things happen, we certainly work our bodies pretty hard so I'm feeling a lot better today,\" LaPorta said.\n"
     ]
    }
   ],
   "source": [
    "query = \"What did Laporta say?\"\n",
    "docs = db.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56639e02-77e0-4272-9143-d9ee70adcc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'Did Gibbs start this week?',\n",
       " 'text': \" I'm sorry, but I don't have access to real-time information about specific players in fantasy football. Can you please provide me with more context or a specific date and time frame so that I can give you an accurate answer?\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\":\"\", \"question\": \"Did Gibbs start this week?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ffb904c2-ffde-4652-9dfc-c8039af0eec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='\"It\\'s football, things happen, we certainly work our bodies pretty hard so I\\'m feeling a lot better today,\" LaPorta said.', metadata={'source': None}),\n",
       "  Document(page_content=\"Rookie tight end Sam LaPorta is questionable with a calf strain that flared up Wednesday, forcing him to miss Thursday's practice. He said it likely stemmed from Sunday's win over Carolina, and he intends to play Sunday.\", metadata={'source': None}),\n",
       "  Document(page_content='\"We don\\'t judge players based off of anything else besides achievement. Like there is success and there is expectations and I want people outside the building to put those expectations on him because, guess what, whether we believe it or not it motivates him. It does and that\\'s a really, really good tool.\"', metadata={'source': None}),\n",
       "  Document(page_content='\"He\\'s right where I thought he would be, he\\'s right where he should be coming along at at this time,\" Scottie Montgomery said.', metadata={'source': None})],\n",
       " 'question': 'What did Laporta say?',\n",
       " 'text': \"\\nSam LaPorta said that he is questionable for Sunday's game due to a calf strain that flared up on Wednesday, causing him to miss Thursday's practice. He stated that it likely occurred during Sunday's win over Carolina and he plans to play on Sunday.\"}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What did Laporta say?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1744a11-d48d-4b77-91b6-c5962402be52",
   "metadata": {},
   "source": [
    "#### Let's try to load the same article with LangChains web crawler loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbfe18a-6add-489f-8b89-c75957a4b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bccb1b-a32f-4986-88b8-ed4230de8226",
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\"https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/\",\n",
    "            \"https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/\",\n",
    "             \"https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15bbffac-c547-4507-b066-e918e6553e74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loader = AsyncChromiumLoader(articles)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31966ec9-96cb-4dda-8ff2-0c671aa785fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "575756a1-52d2-4716-9a59-96b4ab27b397",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4117, which is longer than the specified 100\n",
      "Created a chunk of size 567, which is longer than the specified 100\n",
      "Created a chunk of size 316, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 249, which is longer than the specified 100\n",
      "Created a chunk of size 113, which is longer than the specified 100\n",
      "Created a chunk of size 449, which is longer than the specified 100\n",
      "Created a chunk of size 137, which is longer than the specified 100\n",
      "Created a chunk of size 201, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 479, which is longer than the specified 100\n",
      "Created a chunk of size 216, which is longer than the specified 100\n",
      "Created a chunk of size 138, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 140, which is longer than the specified 100\n",
      "Created a chunk of size 180, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 114, which is longer than the specified 100\n",
      "Created a chunk of size 194, which is longer than the specified 100\n",
      "Created a chunk of size 533, which is longer than the specified 100\n",
      "Created a chunk of size 446, which is longer than the specified 100\n",
      "Created a chunk of size 141, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 317, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 108, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4117, which is longer than the specified 100\n",
      "Created a chunk of size 450, which is longer than the specified 100\n",
      "Created a chunk of size 125, which is longer than the specified 100\n",
      "Created a chunk of size 133, which is longer than the specified 100\n",
      "Created a chunk of size 462, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 469, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 134, which is longer than the specified 100\n",
      "Created a chunk of size 132, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 108, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4117, which is longer than the specified 100\n",
      "Created a chunk of size 178, which is longer than the specified 100\n",
      "Created a chunk of size 422, which is longer than the specified 100\n",
      "Created a chunk of size 282, which is longer than the specified 100\n",
      "Created a chunk of size 498, which is longer than the specified 100\n",
      "Created a chunk of size 164, which is longer than the specified 100\n",
      "Created a chunk of size 413, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 456, which is longer than the specified 100\n",
      "Created a chunk of size 404, which is longer than the specified 100\n",
      "Created a chunk of size 145, which is longer than the specified 100\n",
      "Created a chunk of size 127, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 139, which is longer than the specified 100\n",
      "Created a chunk of size 221, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 121, which is longer than the specified 100\n",
      "Created a chunk of size 380, which is longer than the specified 100\n",
      "Created a chunk of size 234, which is longer than the specified 100\n",
      "Created a chunk of size 123, which is longer than the specified 100\n",
      "Created a chunk of size 230, which is longer than the specified 100\n",
      "Created a chunk of size 346, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 4117, which is longer than the specified 100\n",
      "Created a chunk of size 403, which is longer than the specified 100\n",
      "Created a chunk of size 146, which is longer than the specified 100\n",
      "Created a chunk of size 136, which is longer than the specified 100\n",
      "Created a chunk of size 267, which is longer than the specified 100\n",
      "Created a chunk of size 203, which is longer than the specified 100\n",
      "Created a chunk of size 541, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 300, which is longer than the specified 100\n",
      "Created a chunk of size 324, which is longer than the specified 100\n",
      "Created a chunk of size 281, which is longer than the specified 100\n",
      "Created a chunk of size 305, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 457, which is longer than the specified 100\n",
      "Created a chunk of size 421, which is longer than the specified 100\n",
      "Created a chunk of size 528, which is longer than the specified 100\n",
      "Created a chunk of size 154, which is longer than the specified 100\n",
      "Created a chunk of size 592, which is longer than the specified 100\n",
      "Created a chunk of size 633, which is longer than the specified 100\n",
      "Created a chunk of size 128, which is longer than the specified 100\n",
      "Created a chunk of size 235, which is longer than the specified 100\n",
      "Created a chunk of size 303, which is longer than the specified 100\n",
      "Created a chunk of size 658, which is longer than the specified 100\n",
      "Created a chunk of size 155, which is longer than the specified 100\n",
      "Created a chunk of size 236, which is longer than the specified 100\n",
      "Created a chunk of size 520, which is longer than the specified 100\n",
      "Created a chunk of size 172, which is longer than the specified 100\n",
      "Created a chunk of size 162, which is longer than the specified 100\n",
      "Created a chunk of size 438, which is longer than the specified 100\n",
      "Created a chunk of size 333, which is longer than the specified 100\n",
      "Created a chunk of size 581, which is longer than the specified 100\n",
      "Created a chunk of size 183, which is longer than the specified 100\n",
      "Created a chunk of size 432, which is longer than the specified 100\n",
      "Created a chunk of size 208, which is longer than the specified 100\n",
      "Created a chunk of size 242, which is longer than the specified 100\n",
      "Created a chunk of size 574, which is longer than the specified 100\n",
      "Created a chunk of size 204, which is longer than the specified 100\n",
      "Created a chunk of size 105, which is longer than the specified 100\n",
      "Created a chunk of size 741, which is longer than the specified 100\n",
      "Created a chunk of size 120, which is longer than the specified 100\n",
      "Created a chunk of size 232, which is longer than the specified 100\n",
      "Created a chunk of size 118, which is longer than the specified 100\n",
      "Created a chunk of size 142, which is longer than the specified 100\n",
      "Created a chunk of size 108, which is longer than the specified 100\n",
      "Created a chunk of size 293, which is longer than the specified 100\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(docs_transformed)\n",
    "db = FAISS.from_documents(documents, HuggingFaceEmbeddings(model_name='sentence-transformers/all-mpnet-base-v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44431600-fdd2-4a53-a85c-78603d454efc",
   "metadata": {},
   "source": [
    "What do these documents look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9c2b2675-3704-440b-b0eb-fb3c6c2cfcd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Skip to main content  Skip to navigation', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content=\"Top Events  NCAAF  MLB  NFL  WNBA  F1  NHL  NBA  PGA Tour  NASCAR  Tennis (W)\\nLPGA Tour  NCAAM  Tennis (M)  UFC  NCAAW  Top Soccer  PLL (Lacrosse)  ICC\\nCricket World Cup  Men's NCAA Ice Hockey\", metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content='NFL', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content=\"* Top Events \\n  * NCAAF \\n  * MLB \\n  * NFL \\n  * WNBA \\n  * F1 \\n  * NHL \\n  * NBA \\n  * PGA Tour \\n  * NASCAR \\n  * Tennis (W) \\n  * LPGA Tour \\n  * NCAAM \\n  * Tennis (M) \\n  * UFC \\n  * NCAAW \\n  * Top Soccer \\n  * PLL (Lacrosse) \\n  * ICC Cricket World Cup \\n  * Men's NCAA Ice Hockey\", metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'}),\n",
       " Document(page_content='Week 6\\n\\n  * Week 5 \\n  * Week 6 \\n  * Week 7 \\n\\n<\\n\\nFull Scoreboard \\n\\n>\\n\\n  * Gamecast  Box Score', metadata={'source': 'https://www.espn.com/nfl/story/_/id/38652877/lions-rb-jahmyr-gibbs-wr-amon-ra-st-brown-return-vs-bucs'})]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25209606-6611-4378-bc9d-06da7bca6478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Averaging 45.3 receiving yards per game this season, Alvin Kamara has been a\\nfocal point of the aerial attack with Derek Carr', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       " Document(page_content='at quarterback. Now armed with an upgrade under Center and multiple weapons at\\nwideout to keep the defensive attention off him, Kamara is back to elite\\nreceiving numbers for a running back. Kamara has recorded 36 or more receiving\\nyards in four of his last five games and has topped 33 or more in five of six\\ngames this season. He is being peppered with targets regardless of opponent\\nand should be leaned on again in Week 10. Tap the More on Kamara for Week 10.', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       " Document(page_content='## **Sleeper Picks NFL Week 10**\\n\\n_Season record: 16-20_\\n\\n### **Alvin Kamara (RB  NO)', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       " Document(page_content='at quarterback. Kamara has averaged 42.8 receiving yards per game over his\\ncareer but saw a dip in consecutive years with Andy Dalton', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = db.as_retriever()\n",
    "retriever.invoke(\"what do you think about alvin kamara?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c05f00-a339-44ce-b985-cff6df8930ea",
   "metadata": {},
   "source": [
    "Super noisy but let's still see how it performs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19dbb99e-71b0-4cf7-b59c-f4112898dddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': '',\n",
       " 'question': 'Should I pick up Alvin Kamara for my fantasy team?',\n",
       " 'text': '\\nWhether or not you should pick up Alvin Kamara for your fantasy team depends on a few factors, such as the specific league rules and roster requirements, the current performance of Kamara and other players in your league, and your overall strategy for building your team.\\n\\nIn general, Kamara is considered to be one of the top running backs in the NFL and has had a strong season so far. He has been a consistent producer of points for his owners, with multiple touchdown'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\"context\":\"\", \"question\": \"Should I pick up Alvin Kamara for my fantasy team?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16b4b91a-f8ca-461a-a35d-f17230782191",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()\n",
    "\n",
    "chain = ( \n",
    " {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | llm_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43df7c50-e13f-444b-be21-2486891a2fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='at quarterback. Now armed with an upgrade under Center and multiple weapons at\\nwideout to keep the defensive attention off him, Kamara is back to elite\\nreceiving numbers for a running back. Kamara has recorded 36 or more receiving\\nyards in four of his last five games and has topped 33 or more in five of six\\ngames this season. He is being peppered with targets regardless of opponent\\nand should be leaned on again in Week 10. Tap the More on Kamara for Week 10.', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       "  Document(page_content='## **Sleeper Picks NFL Week 10**\\n\\n_Season record: 16-20_\\n\\n### **Alvin Kamara (RB  NO)', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       "  Document(page_content=', as he should have plenty of field goal opportunities to both miss and make.\\nAt running back, I will be going with CMC and Alvin Kamara', metadata={'source': 'https://www.fantasypros.com/2023/11/rival-fantasy-nfl-week-10/'}),\n",
       "  Document(page_content='Averaging 45.3 receiving yards per game this season, Alvin Kamara has been a\\nfocal point of the aerial attack with Derek Carr', metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'})],\n",
       " 'question': 'Should I pick up Alvin Kamara for my fantasy team?',\n",
       " 'text': ' Based on the information provided, it seems that Alvin Kamara has been performing well as a running back in the NFL. He has recorded 36 or more receiving yards in four of his last five games and has topped 33 or more in five of six games this season. He is also being peppered with targets regardless of opponent, which suggests that he is a valuable asset to have on your fantasy team. Additionally, he has field goal opportunities, which could provide additional points for'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Should I pick up Alvin Kamara for my fantasy team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7c6174df-7599-4d01-bd02-7f4b451da1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content=' **Josh Jacobs** is coming off his second-best game of the season in week\\nnine. While Jacobs has had more success, he still runs at 3.2 YPC. I cant\\nimagine the team competing with a rookie quarterback. Jocabs has the sixth-\\nhardest remaining schedule of the season for fantasy running backs. Lets not\\nforget he still has a bye week to deal with. Id be looking to sell high on\\nJacobs to acquire like DeVon Achane or Tony Pollard', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content='Kareem Hunt is the fourth highest when it relates to inside the 5 rushing\\nattempt percentage in the ENTIRE NFL. He has played six games and didnt even\\nstart on a roster to begin the 2023 season. With the Cleveland Browns, Jerome\\nFord has been pushed into the Between the 20s running back who needs a\\nhomerun shot to bring your fantasy team a ceiling play. Kareem Hunt is the\\nhammer that finishes off the drives for the Browns. With Deshaun Watson', metadata={'source': 'https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/'}),\n",
       "  Document(page_content='Hopkins. Who would I try to get in return for JaMarr Chase? The same players\\nI listed above in the Saquon deal, or if that wasnt possible, maybe a one-\\nfor-one swap for Travis Kelce', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content='dealing with injury, the Browns will continue to lean on their running backs.\\nHunt should provide a Walmart version of David Montgomery', metadata={'source': 'https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/'})],\n",
       " 'question': 'I have Josh Jacobs, should I trade him for Kareem Hunt?',\n",
       " 'text': \"\\nBased on the information provided, it seems that Josh Jacobs may be facing some challenges in terms of competition and schedule. However, it's important to note that he still has a bye week to deal with. On the other hand, Kareem Hunt has been playing well for the Cleveland Browns and has a strong inside the 5 rushing attempt percentage.\\n\\nIf you are considering trading Josh Jacobs for Kareem Hunt, it's important to consider the potential impact on your overall team. You may want to consider acquiring other players to balance out your lineup and ensure that you have a diverse range of options. Additionally, you may want to consider the long-term potential of both players and whether they align with your overall strategy for the rest of the season. Ultimately, the decision to trade Josh Jacobs for Kareem Hunt should be based on careful consideration of all relevant factors and your overall goals for the season.\"}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"I have Josh Jacobs, should I trade him for Kareem Hunt?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "484b3341-ab7c-49b9-a816-b62caecd93c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context': [Document(page_content='### **JaMarr Chase (WR  CIN)\\n\\n**', metadata={'source': 'https://www.fantasypros.com/2023/11/players-to-buy-low-sell-high-trade-advice-2023-fantasy-football/'}),\n",
       "  Document(page_content=\"Ja'Marr Chase\\n\\n(back) at practice Friday\\n\\nAmon-Ra St. Brown\", metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-week-10-sleeper-picks-player-predictions-2023/'}),\n",
       "  Document(page_content=\"Ja'Marr Chase\\n\\n(back) at practice Friday\\n\\nAmon-Ra St. Brown\", metadata={'source': 'https://www.fantasypros.com/2023/11/5-stats-to-know-before-setting-your-fantasy-lineup-week-10/'}),\n",
       "  Document(page_content=\"Ja'Marr Chase\\n\\n(back) at practice Friday\\n\\nAmon-Ra St. Brown\", metadata={'source': 'https://www.fantasypros.com/2023/11/nfl-dfs-week-10-stacking-advice-picks-2023-fantasy-football/'})],\n",
       " 'question': \"What are your thoughts on Ja'Marr Chase going into this week?\",\n",
       " 'text': \" Based on the information provided, it seems that Ja'Marr Chase is currently practicing and may be available for play in Week 10 of the NFL season. While there is no specific information about his performance or injury status, it is worth noting that he has been mentioned as a potential sleeper pick and stacking advice for DFS players. Additionally, there have been several articles discussing his potential impact on the Bengals offense and his role in their success. Overall, while there may be some uncertainty around his performance, it appears that Ja'Marr Chase could be a valuable addition to any fantasy football team looking for a reliable wide receiver option.\"}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are your thoughts on Ja'Marr Chase going into this week?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d24ce6-ed21-4a50-bd63-68bea318940d",
   "metadata": {},
   "source": [
    "Sweet, still gives the right answer! This may cause issues as we add more docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f976ad-7b7e-420a-871e-c70d78fd65de",
   "metadata": {},
   "source": [
    "### Conversational Retrieval Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0156d5c-091f-46c8-b08e-9be394ca62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableMap\n",
    "from langchain.schema import format_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f597679-51a8-48ed-a5bb-36fa7a985fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"[INST] Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\n",
    "[/INST]\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ff5d234-27ff-4bf1-b1d1-8f6710b7e99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST]Answer the question based only on the following context and chat history:\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Question: {question}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35b8f9af-b67d-4a7e-9f0a-e10c3417fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create llm chain \n",
    "llm_chain_cq = LLMChain(llm=mistral_llm_0_temp, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "# Create llm chain \n",
    "llm_chain_a = LLMChain(llm=mistral_llm, prompt=ANSWER_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d7e1676-88a6-497c-a614-24475050d976",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "def _combine_documents(docs, document_prompt = DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4dc451df-c7bd-4a21-8297-bf85bbc05c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def _format_chat_history(chat_history: List[Tuple]) -> str:\n",
    "    buffer = \"\"\n",
    "    for dialogue_turn in chat_history:\n",
    "        human = \"Me: \" + dialogue_turn[0]\n",
    "        ai = \"Assistant: \" + dialogue_turn[1]\n",
    "        buffer += \"\\n\" + \"\\n\".join([human, ai])\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b06ac007-0d4a-47c4-b146-5144274c8571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  standalone_question: RunnableAssign(mapper={\n",
       "                         chat_history: RunnableLambda(...)\n",
       "                       })\n",
       "}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x['chat_history']))\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72c5ad79-13e6-42e5-8491-63fc86fbc5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_standalone_question(data):\n",
    "    return data['standalone_question']['text']\n",
    "\n",
    "def get_chathistory_from_standalone_question(data):\n",
    "    return data['standalone_question']['chat_history']\n",
    "\n",
    "_inputs = RunnableMap(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: _format_chat_history(x['chat_history'])\n",
    "    ) | llm_chain_cq ,\n",
    ")\n",
    "_context = {\n",
    "    \"chat_history\": get_chathistory_from_standalone_question,\n",
    "    \"context\": get_text_from_standalone_question  | retriever | _combine_documents,\n",
    "    \"question\": get_text_from_standalone_question\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | llm_chain_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f64a3186-2f1b-4782-ba0c-34f5d3b72d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'standalone_question': {'question': 'What was Gibbs injury?',\n",
       "  'chat_history': '',\n",
       "  'text': \" What was Gibbs' injury?\"}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_inputs.invoke({\n",
    "    \"question\": \"What was Gibbs injury?\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f0da6e8b-9c1a-4209-8293-ec9bdbb815dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': '',\n",
       " 'context': \"Meanwhile, rookie safety Brian Branch, who has an ankle injury, is also set to miss his second consecutive game. The second-round pick out of Alabama was held out of practice for the entire week. With 25 tackles, a pick-six and 4 passes defended, he is Detroit's fourth-leading tackler.\\n\\nVeteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\\n\\nGibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\\n\\nALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\",\n",
       " 'question': ' What is the definition of an active roster in the NFL?',\n",
       " 'text': '\\nThe definition of an active roster in the NFL refers to the group of players that are currently available to participate in games for a particular team. Each NFL team is allowed to have a maximum of 53 players on its active roster at any given time during the regular season. These players are typically the ones who will be suiting up for games and playing on the field. However, teams can also have a smaller number of players on their active roster if they choose to use roster spots for other purposes, such as practice squad players or injured reserve designations.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"What does active roster mean in NFL?\",\n",
    "    \"chat_history\": [],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5350d7dc-b5b0-4eda-b16a-98a263cc5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chat_history': '\\nMe: What was Gibbs injury?\\nAssistant: Gibbs suffered a hamstring injury.\\nMe: W\\nAssistant: h\\nMe: G\\nAssistant: i',\n",
       " 'context': \"Although expectations are high for Gibbs as the Lions' No. 12 overall selection, running back coach Scottie Montgomery is helping him develop at his own pace.\\n\\nGibbs, who did not practice this week, also missed last week's 42-24 victory over the Carolina Panthers with the same injury. With 179 yards and a touchdown with an additional 70 receiving yards in his four appearances, he is Detroit's second-leading rusher.\\n\\nALLEN PARK, Mich. -- Detroit Lions running back Jahmyr Gibbs has been ruled out for Sunday's game against the Tampa Bay Buccaneers with a hamstring injury while Pro Bowl receiver Amon-Ra St. Brown (abdomen) is set to make his return.\\n\\nVeteran running back David Montgomery has carried the load in his absence, with back-to-back games of at least 100 yards rushing. Detroit has rushed for nine touchdowns through the first five games of the season, tying a team record.\",\n",
       " 'question': \" Who is Gibbs' running back coach?\",\n",
       " 'text': \"Gibbs' running back coach is Scottie Montgomery.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke({\n",
    "    \"question\": \"Who is his running back coach?\",\n",
    "    \"chat_history\": [(\"What was Gibbs injury?\", \"Gibbs suffered a hamstring injury.\"),\n",
    "                     (\"Who are we talking about?\"),(\"Gibbs is a running back for the Detroit Lions. He was their No. 12 overall selection in the 2021 NFL Draft and has been ruled out of their upcoming game against the Tampa Bay Buccaneers due to a hamstring injury. Despite high expectations, running back coach Scottie Montgomery is helping him develop at his own pace.\")],\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc391b-9616-4a18-b51f-c7c9d556ca2c",
   "metadata": {},
   "source": [
    "### Add Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bec9b30-af90-42ae-9868-6734810ae891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-13.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-13:m111"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
